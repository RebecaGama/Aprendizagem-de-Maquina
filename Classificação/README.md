<h1 align="center"> Classifica√ß√£o </h1>

## üß† Sobre o Projeto

<div align="justify">

Este projeto tem como objetivo desenvolver um modelo de **classifica√ß√£o de sentimentos** a partir de **resenhas de filmes**.  
A ideia central √© construir um classificador capaz de prever se uma resenha √© **positiva** ou **negativa** com base apenas no seu conte√∫do textual.

</div>

##

## üìÇ Base de Dados

- **Fonte:** IMDb Movie Reviews Dataset  
  - Dispon√≠vel em: [Kaggle](https://www.kaggle.com/)
- **Idioma:** Ingl√™s
  - Todas as resenhas est√£o escritas em ingl√™s.
- **Tamanho:**
  - 50.000 registros (resenhas de filmes)
  - Divididos igualmente entre 25.000 resenhas positivas e 25.000 resenhas negativas
  - Arquivo .csv com cerca de 80 MB
- **Descri√ß√£o:**
  - `review`: Texto da resenha do filme.
  - `sentiment`: R√≥tulo da resenha:
    - `positive` (1): Resenha positiva.
    - `negative` (0): Resenha negativa.

##

## üéØ Objetivo

Classificar automaticamente resenhas de filmes como **positivas** ou **negativas** por meio de t√©cnicas de Processamento de Linguagem Natural (PLN) e Aprendizagem de M√°quina.

> ‚úÖ Projeto finalizado.

##

## üßπ Pr√©-processamento dos Dados

As etapas de tratamento inclu√≠ram:

- **Limpeza do texto:**  
  Remo√ß√£o de pontua√ß√µes, n√∫meros e convers√£o para letras min√∫sculas.
  
- **Stopwords:**  
  Exclus√£o de palavras comuns irrelevantes (usando `nltk.stopwords`).
  
- **Tokeniza√ß√£o:**  
  Separa√ß√£o do texto em palavras individuais.
  
- **Stemming:**  
  Redu√ß√£o das palavras √† sua raiz (com `PorterStemmer`).

- **Convers√£o de r√≥tulos:**  
  `positive` ‚Üí 1  
  `negative` ‚Üí 0

##

## ‚öôÔ∏è Algoritmos Utilizados

Foram testados cinco algoritmos de classifica√ß√£o:

1. **Naive Bayes**
2. **√Årvore de Decis√£o**
3. **Random Forest**
4. **Support Vector Machine (SVM)**
5. **Rede Neural**

##

## üìä Resultados

### üü° **Naive Bayes**
- Melhor **recall** para classe 0 (negativa).
- Boa **precis√£o** para classe 1 (positiva).
- **Acur√°cia:** 85%

![Naive Bayes](https://github.com/user-attachments/assets/dcf06660-cf52-4138-a019-870874a99d16)

###  **√Årvore de Decis√£o**
- Maior sensibilidade para a classe 0 (negativa), e menor desempenho para classe 1 (positiva).
- **F1-Score m√©dio:** 0.69
- **Acur√°cia:** 69%

![√Årvore de Decis√£o](https://github.com/user-attachments/assets/1fb2dbaa-1f7c-4d96-b1b8-fab281c15fb2)

###  **Random Forest**
- Modelo robusto, com boa capacidade de generaliza√ß√£o.
- Resultados equilibrados entre precis√£o e recall nas duas classes.
- **Acur√°cia:** 85%

![Random Forest](https://github.com/user-attachments/assets/82cda757-3d26-40d3-a6c4-fd918822736f)

### üîµ **SVM**
- Melhor equil√≠brio entre precis√£o e recall para ambas as classes.
- **F1-score:** 0.86 (positiva) e 0.85 (negativa).
- **Acur√°cia:** 84%

 ![Support Vector Machine](https://github.com/user-attachments/assets/cc15073b-8571-46b7-bb07-ecbcc22291c4)

###  **Rede Neural**
- Modelo complexo
- Obteve m√©tricas pr√≥ximas ao SVM, mostrando bom poder preditivo.
- **Acur√°cia:** 81%

![Rede Neural](https://github.com/user-attachments/assets/5ea5261a-b527-44d2-a442-c99e70676650)

##

## üîß Ajustes de Par√¢metros

### üìå Support Vector Machine
- **Melhor configura√ß√£o:**  
  - `C=1`, `kernel='linear'`, `class_weight='balanced'`
- **Resultado:**  
  - Acur√°cia: 85%  
  - F1-score balanceado (0.85 e 0.84)  
  - Boa performance nas duas classes.

![SVM Ajustado](https://github.com/user-attachments/assets/6f9c251c-647c-479a-93e6-0f73d266a1fe)

### üìå √Årvore de Decis√£o
- **Desempenho inicial:** Acur√°cia de 73%
- **Ajustes realizados:**
  - **GridSearchCV** para otimizar:
    - `max_depth`
    - `min_samples_split`
    - `min_samples_leaf`
    - `criterion`
  - Uso de `class_weight='balanced'` para lidar com classes desbalanceadas.
- **Resultados ap√≥s ajuste:**
  - Recall da classe 1 subiu de 0.69 ‚Üí 0.79
  - Recall da classe 0 caiu de 0.77 ‚Üí 0.60
  - Acur√°cia geral caiu levemente para 69%, mas houve maior sensibilidade para resenhas positivas.

![√Årvore de Decis√£o Ajustada](https://github.com/user-attachments/assets/b25d1939-5e12-4f29-97cc-1020576c6693)

##

## ‚úÖ Conclus√£o

- **Naive Bayes** se destacou em avalia√ß√µes negativas, mas com vi√©s percept√≠vel.
- **SVM** teve o melhor desempenho global, sendo mais equilibrado e indicado para uso em produ√ß√£o.
- **√Årvore de Decis√£o**, apesar de menos precisa, ofereceu boa interpretabilidade e sensibilidade para a classe positiva.
- üéØ **Objetivo atingido**: Desenvolver modelos eficientes de classifica√ß√£o de sentimentos com base em texto.
